{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b76eab",
   "metadata": {},
   "source": [
    "# **EEG Brain Age â€“ Random Forest Genetic Algorithm + BAG  (Final 2025)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f6665",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708e51be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ale\\Downloads\\Jade\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7b337",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf58a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded: 510 samples, 10 columns\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"C:\\Users\\Ale\\Downloads\\Jade\\Ale\\Data_Parametrizada\\EEG_features_final.csv\"\n",
    "SAVE_DIR = r\"C:\\Users\\Ale\\Downloads\\Jade\\Ale\\Jade_Saves\\Results_RF_Genetic\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "print(f\" Dataset loaded: {df.shape[0]} samples, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc9622",
   "metadata": {},
   "source": [
    "## **Feature engineering**\n",
    "Feature engineering consiste en crear nuevas variables a partir de las bandas EEG para representar mejor la actividad cerebral. En este caso, se usan sumas, razones entre bandas y transformaciones matemÃ¡ticas para capturar relaciones neurofisiolÃ³gicas relevantes, reducir ruido y facilitar el aprendizaje de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0cc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(col in df.columns for col in [\"Delta\",\"Theta\",\"Alpha\",\"Beta\",\"Gamma\"]):\n",
    "    df[\"TotalPower\"] = df[[\"Delta\",\"Theta\",\"Alpha\",\"Beta\",\"Gamma\"]].sum(axis=1)\n",
    "    df[\"Theta_Alpha\"] = df[\"Theta\"] / (df[\"Alpha\"] + 1e-6)\n",
    "    df[\"Alpha_Beta\"]  = df[\"Alpha\"] / (df[\"Beta\"] + 1e-6)\n",
    "    df[\"Delta_Alpha\"] = df[\"Delta\"] / (df[\"Alpha\"] + 1e-6)\n",
    "    df[\"Beta_Gamma\"]  = df[\"Beta\"]  / (df[\"Gamma\"] + 1e-6)\n",
    "    df[\"Slow_Fast\"]   = (df[\"Delta\"] + df[\"Theta\"]) / (df[\"Alpha\"] + df[\"Beta\"] + 1e-6)\n",
    "\n",
    "    for col in [\"Delta\",\"Theta\",\"Alpha\",\"Beta\",\"Gamma\"]:\n",
    "        df[f\"log_{col}\"] = np.log1p(df[col])\n",
    "        df[f\"sqrt_{col}\"] = np.sqrt(df[col])\n",
    "\n",
    "X = df.drop(columns=[\"Age\"])\n",
    "y = df[\"Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62923dd",
   "metadata": {},
   "source": [
    "Z-score filtering was applied to remove outliers, features were standardized to ensure equal scaling, and balanced sample weights were used to reduce bias caused by uneven target distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9434046",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(X))\n",
    "filtered_entries = (z_scores < 3).all(axis=1)\n",
    "X = X[filtered_entries].reset_index(drop=True)\n",
    "y = y[filtered_entries].reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Balanced sample weights\n",
    "bins = pd.cut(y, bins=5, labels=False)\n",
    "weights = 1 / np.bincount(bins)\n",
    "sample_weights = np.array([weights[b] for b in bins])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a1ff7",
   "metadata": {},
   "source": [
    "# **Training MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6102eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f03c3",
   "metadata": {},
   "source": [
    "## **Bayesian hyperparameter optimization using Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112fae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Evaluating initial population...\n",
      "\n",
      "  Individual 1/10\n",
      "    â–¶ Training RF | Trees=310 | Depth=38 | Split=10 | Leaf=1 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.7828\n",
      "\n",
      "  Individual 2/10\n",
      "    â–¶ Training RF | Trees=407 | Depth=23 | Split=8 | Leaf=2 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.7836\n",
      "\n",
      "  Individual 3/10\n",
      "    â–¶ Training RF | Trees=203 | Depth=9 | Split=7 | Leaf=5 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.6554\n",
      "\n",
      "  Individual 4/10\n",
      "    â–¶ Training RF | Trees=702 | Depth=15 | Split=10 | Leaf=4 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.6999\n",
      "\n",
      "  Individual 5/10\n",
      "    â–¶ Training RF | Trees=501 | Depth=40 | Split=10 | Leaf=1 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.7815\n",
      "\n",
      "  Individual 6/10\n",
      "    â–¶ Training RF | Trees=264 | Depth=38 | Split=9 | Leaf=4 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.6941\n",
      "\n",
      "  Individual 7/10\n",
      "    â–¶ Training RF | Trees=611 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8417\n",
      "\n",
      "  Individual 8/10\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "  Individual 9/10\n",
      "    â–¶ Training RF | Trees=720 | Depth=8 | Split=8 | Leaf=1 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.7542\n",
      "\n",
      "  Individual 10/10\n",
      "    â–¶ Training RF | Trees=309 | Depth=11 | Split=7 | Leaf=3 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.7637\n",
      "\n",
      "\n",
      "================ GENERATION 1/5 ================\n",
      " Re-evaluating 5 offspring...\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8417\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=202 | Depth=8 | Split=8 | Leaf=2 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.7304\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8417\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "\n",
      "================ GENERATION 2/5 ================\n",
      " Re-evaluating 10 offspring...\n",
      "\n",
      "    â–¶ Training RF | Trees=720 | Depth=38 | Split=10 | Leaf=1 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.7848\n",
      "\n",
      "    â–¶ Training RF | Trees=310 | Depth=8 | Split=8 | Leaf=1 | Feat=log2\n",
      "    âœ” Finished | RÂ² = 0.7497\n",
      "\n",
      "    â–¶ Training RF | Trees=370 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8983\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8418\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8996\n",
      "\n",
      "    â–¶ Training RF | Trees=575 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8410\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8996\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=21 | Split=7 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8418\n",
      "\n",
      "\n",
      "================ GENERATION 3/5 ================\n",
      " Re-evaluating 6 offspring...\n",
      "\n",
      "    â–¶ Training RF | Trees=558 | Depth=37 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8988\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8996\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "\n",
      "================ GENERATION 4/5 ================\n",
      " Re-evaluating 10 offspring...\n",
      "\n",
      "    â–¶ Training RF | Trees=761 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8998\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8996\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=611 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.8996\n",
      "\n",
      "\n",
      "================ GENERATION 5/5 ================\n",
      " Re-evaluating 5 offspring...\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=5 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.6729\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "    â–¶ Training RF | Trees=262 | Depth=40 | Split=3 | Leaf=1 | Feat=sqrt\n",
      "    âœ” Finished | RÂ² = 0.9003\n",
      "\n",
      "\n",
      "================ BEST RF MODEL FOUND ================\n",
      "n_estimators: 262\n",
      "max_depth: 40\n",
      "min_samples_split: 3\n",
      "min_samples_leaf: 1\n",
      "max_features: sqrt\n",
      "Best RÂ²: 0.9002665312214304\n"
     ]
    }
   ],
   "source": [
    "# ===================== IMPORTS =====================\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ===================== FITNESS =====================\n",
    "# âš ï¸ Restart kernel before running if already defined\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# ===================== INDIVIDUAL =====================\n",
    "def random_individual():\n",
    "    n_estimators = random.randint(200, 800)\n",
    "    max_depth = random.randint(5, 40)\n",
    "    min_samples_split = random.randint(2, 10)\n",
    "    min_samples_leaf = random.randint(1, 5)\n",
    "    max_features = random.choice([\"sqrt\", \"log2\"])\n",
    "\n",
    "    return creator.Individual([\n",
    "        n_estimators,\n",
    "        max_depth,\n",
    "        min_samples_split,\n",
    "        min_samples_leaf,\n",
    "        max_features\n",
    "    ])\n",
    "\n",
    "# ===================== BUILD MODEL =====================\n",
    "def build_ga_rf(individual):\n",
    "    return RandomForestRegressor(\n",
    "        n_estimators=individual[0],\n",
    "        max_depth=individual[1],\n",
    "        min_samples_split=individual[2],\n",
    "        min_samples_leaf=individual[3],\n",
    "        max_features=individual[4],\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# ===================== EVALUATE =====================\n",
    "def evaluate(individual):\n",
    "    print(\n",
    "        f\"    â–¶ Training RF | \"\n",
    "        f\"Trees={individual[0]} | \"\n",
    "        f\"Depth={individual[1]} | \"\n",
    "        f\"Split={individual[2]} | \"\n",
    "        f\"Leaf={individual[3]} | \"\n",
    "        f\"Feat={individual[4]}\"\n",
    "    )\n",
    "\n",
    "    model = build_ga_rf(individual)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        sample_weight=sample_weights[y_train.index]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"    âœ” Finished | RÂ² = {r2:.4f}\\n\")\n",
    "    return (r2,)\n",
    "\n",
    "# ===================== MUTATION =====================\n",
    "def mutate_individual(individual, indpb=0.2):\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = random.randint(200, 800)       # n_estimators\n",
    "    if random.random() < indpb:\n",
    "        individual[1] = random.randint(5, 40)          # max_depth\n",
    "    if random.random() < indpb:\n",
    "        individual[2] = random.randint(2, 10)          # min_samples_split\n",
    "    if random.random() < indpb:\n",
    "        individual[3] = random.randint(1, 5)           # min_samples_leaf\n",
    "    if random.random() < indpb:\n",
    "        individual[4] = random.choice([\"sqrt\", \"log2\"])# max_features\n",
    "\n",
    "    return (individual,)\n",
    "\n",
    "# ===================== TOOLBOX =====================\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", random_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutate_individual)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# ===================== GA RUN =====================\n",
    "POP_SIZE = 10\n",
    "N_GEN = 5\n",
    "CX_PROB = 0.7\n",
    "MUT_PROB = 0.2\n",
    "\n",
    "population = toolbox.population(n=POP_SIZE)\n",
    "\n",
    "print(\"\\nðŸ”¹ Evaluating initial population...\\n\")\n",
    "for i, ind in enumerate(population):\n",
    "    print(f\"  Individual {i+1}/{POP_SIZE}\")\n",
    "    ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "for gen in range(N_GEN):\n",
    "    print(f\"\\n================ GENERATION {gen + 1}/{N_GEN} ================\")\n",
    "\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CX_PROB:\n",
    "            toolbox.mate(c1, c2)\n",
    "            del c1.fitness.values, c2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUT_PROB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    print(f\" Re-evaluating {len(invalid)} offspring...\\n\")\n",
    "\n",
    "    for ind in invalid:\n",
    "        ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "    population[:] = offspring\n",
    "\n",
    "# ===================== BEST RESULT =====================\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "\n",
    "print(\"\\n================ BEST RF MODEL FOUND ================\")\n",
    "print(\"n_estimators:\", best_ind[0])\n",
    "print(\"max_depth:\", best_ind[1])\n",
    "print(\"min_samples_split:\", best_ind[2])\n",
    "print(\"min_samples_leaf:\", best_ind[3])\n",
    "print(\"max_features:\", best_ind[4])\n",
    "print(\"Best RÂ²:\", best_ind.fitness.values[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d7a6d",
   "metadata": {},
   "source": [
    "### **Train Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f91a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final Random Forest with GA best hyperparameters...\n",
      "{'n_estimators': 262, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params = {\n",
    "    \"n_estimators\": best_ind[0],\n",
    "    \"max_depth\": best_ind[1],\n",
    "    \"min_samples_split\": best_ind[2],\n",
    "    \"min_samples_leaf\": best_ind[3],\n",
    "    \"max_features\": best_ind[4],\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nTraining final Random Forest with GA best hyperparameters...\")\n",
    "print(best_params)\n",
    "\n",
    "rf_best = RandomForestRegressor(\n",
    "    **best_params,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fresh split (important for robustness)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "rf_best.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=sample_weights[y_train.index]\n",
    ")\n",
    "\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97979853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FINAL TEST RESULTS =================\n",
      "MAE (years): 4.52\n",
      "RÂ²: 0.900\n",
      "Pearson r: 0.965\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "\n",
    "print(\"\\n================ FINAL TEST RESULTS =================\")\n",
    "print(f\"MAE (years): {mae:.2f}\")\n",
    "print(f\"RÂ²: {r2:.3f}\")\n",
    "print(f\"Pearson r: {r:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25455395",
   "metadata": {},
   "source": [
    "### **BAG Calculation and Categorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c51d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n"
     ]
    }
   ],
   "source": [
    "BAG = y_pred - y_test.values\n",
    "bag_mean, bag_std = BAG.mean(), BAG.std()\n",
    "print(f\"\\n Brain Age Gap (BAG): mean={bag_mean:.2f}, std={bag_std:.2f}\")\n",
    "\n",
    "def categorize_bag(bag):\n",
    "    if bag < -3: return \"Resilient\"\n",
    "    elif bag > 3: return \"Accelerated\"\n",
    "    else: return \"Normal\"\n",
    "\n",
    "bag_categories = np.vectorize(categorize_bag)(BAG)\n",
    "bag_df = pd.DataFrame({\n",
    "    \"Chronological_Age\": y_test.values,\n",
    "    \"Predicted_Age\": y_pred,\n",
    "    \"BAG\": BAG,\n",
    "    \"Category\": bag_categories\n",
    "})\n",
    "bag_df.to_csv(os.path.join(SAVE_DIR, \"EEG_Brain_Age_Gap_RF.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22a46a",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b802b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG histogram\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(BAG, bins=25, color=\"lightcoral\", edgecolor=\"black\")\n",
    "plt.axvline(0, color=\"blue\", linestyle=\"--\")\n",
    "plt.title(\"Brain Age Gap (Predicted - Chronological) â€“ Random Forest\")\n",
    "plt.xlabel(\"BAG (years)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, \"bag_hist_RF.png\"))\n",
    "plt.close()\n",
    "\n",
    "# BAG categories\n",
    "plt.figure(figsize=(6,4))\n",
    "pd.Series(bag_categories).value_counts().reindex([\"Resilient\",\"Normal\",\"Accelerated\"]).plot(kind=\"bar\", color=[\"#66c2a5\",\"#fc8d62\",\"#8da0cb\"])\n",
    "plt.title(\"BAG Categories Distribution (Â±3 years)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis=\"y\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, \"bag_categories_RF.png\"))\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec69924",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30441d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rf_best.feature_importances_\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "feat_imp.to_csv(os.path.join(SAVE_DIR, \"RF_feature_importance.csv\"), index=False)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feat_imp[\"Feature\"][:10], feat_imp[\"Importance\"][:10], color=\"darkorange\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Feature Importances â€“ Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, \"RF_feature_importance.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dea40a",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e760c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n Computing permutation importance...\")\n",
    "perm_result = permutation_importance(\n",
    "    rf_best, X_test, y_test, n_repeats=10, random_state=42, scoring=\"r2\"\n",
    ")\n",
    "perm_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": perm_result.importances_mean\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "perm_df.to_csv(os.path.join(SAVE_DIR, \"RF_permutation_importance.csv\"), index=False)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(perm_df[\"Feature\"][:10], perm_df[\"Importance\"][:10], color=\"goldenrod\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Features â€“ Permutation Importance (RF)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, \"RF_permutation_importance.png\"))\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d6498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All Random Forest results saved in: C:\\Users\\Ale\\Downloads\\Jade\\Ale\\Jade_Saves\\Results_RF_Genetic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame([{\n",
    "    \"MAE\": mae, \"R2\": r2, \"r\": r, \"BAG_mean\": bag_mean, \"BAG_std\": bag_std,\n",
    "    \"Best_Params\": best_params\n",
    "}]).to_csv(os.path.join(SAVE_DIR, \"RF_final_results.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n All Random Forest results saved in: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5efae",
   "metadata": {},
   "source": [
    "### Comparison Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac022872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BAG_stadistics(y_pred, y_test):\n",
    "    BAG = y_pred - y_test.values\n",
    "    bag_mean, bag_std = BAG.mean(), BAG.std()\n",
    "    print(f\"\\n Brain Age Gap (BAG): mean={bag_mean:.2f}, std={bag_std:.2f}\")\n",
    "    return bag_mean, bag_std\n",
    "\n",
    "    \n",
    "def comparison_trials(n_trials, best_params, X_scaled, y):\n",
    "    results = []\n",
    "    for i in range(n_trials):\n",
    "        print(\"\\nTraining final model with best hyperparameters...\")\n",
    "        print(\"Trial:\", i+1)\n",
    "        \n",
    "        rf_best = RandomForestRegressor(\n",
    "            **best_params,\n",
    "            bootstrap=True,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled,\n",
    "            y,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        rf_best.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            sample_weight=sample_weights[y_train.index]\n",
    "        )\n",
    "\n",
    "        y_pred = rf_best.predict(X_test)\n",
    "\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "        bag_mean, bag_std = BAG_stadistics(y_pred, y_test)\n",
    "\n",
    "        results.append({\n",
    "    \"Trial\": i + 1,\n",
    "    \"MAE\": mae,\n",
    "    \"R2\": r2,\n",
    "    \"Pearson_r\": r,\n",
    "    \"BAG_mean\": bag_mean,\n",
    "    \"BAG_std\": bag_std,\n",
    "    \"Model\": \"RandomForest\",\n",
    "    \"N_estimators\": best_params[\"n_estimators\"],\n",
    "    \"Max_depth\": best_params[\"max_depth\"]\n",
    "        })\n",
    "\n",
    "\n",
    "    # save once at the end\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\n",
    "        os.path.join(SAVE_DIR, \"TRIALS_RF_Optuna_Genetic.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\nAll results saved in: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d18093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 1\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 2\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 3\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 4\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 5\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 6\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 7\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 8\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 9\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 10\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 11\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 12\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 13\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 14\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 15\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 16\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 17\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 18\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 19\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Trial: 20\n",
      "\n",
      " Brain Age Gap (BAG): mean=-0.74, std=6.63\n",
      "\n",
      "All results saved in: C:\\Users\\Ale\\Downloads\\Jade\\Ale\\Jade_Saves\\Results_RF_Genetic\n",
      "\n",
      " Total comparison trials time: 5.67 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "star_time = time.time()\n",
    "n=20\n",
    "comparison_trials(20, best_params, X_scaled, y)\n",
    "end_time = time.time()\n",
    "print(f\"\\n Total comparison trials time: {end_time - star_time:.2f} seconds\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f89e1a",
   "metadata": {},
   "source": [
    "Trials Time: 5,67 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
